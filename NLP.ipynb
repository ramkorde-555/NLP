{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb4fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87120411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e1e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006ee26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6ac55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e78f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19425c0",
   "metadata": {},
   "source": [
    "## Text Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ed3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'Reaching out for HELP. Please meet me in LONDON at 6 a.m xyz@abc.com #urgent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba542ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional stopwords\n",
    "extra_list = ['let', 'may', 'might', 'must', 'need', 'apologies', 'meet']\n",
    "stopword = stopwords.words('english')\n",
    "stopword.extend(extra_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b63428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ' '.join([i for i in line.split() if i not in stopword])\n",
    "line = line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8c25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0efd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reaching', 'help.', 'please', 'london', '6', 'a.m', 'xyz@abc.com', '#urgent']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a08532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_porter(text):\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    ps = nltk.PorterStemmer()\n",
    "    return [ps.stem(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566776a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reach', 'help.', 'pleas', 'london', '6', 'a.m', 'xyz@abc.com', '#urgent']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_porter(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28cf16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = re.sub('\\S*@\\S*\\s?',\" \",line) #email remove\n",
    "line = re.sub('\\s+',\" \",line) #new line character remove\n",
    "line = re.sub(\"\\'\",\" \",line) #single quote remove\n",
    "line = re.sub('_',\" \",line) #underscore remove\n",
    "line = re.sub('http\\S*\\s?',\" \",line) #link remove\n",
    "line = ' '.join([i for i in line.split() if i.find('#') < 0]) #hasgtag remove\n",
    "line = ' '.join([i for i in line.split() if i in re.findall(r'\\w+',line)]) #only keep words and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec04d21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reaching please london 6'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b22f2588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reaching :  VERB :  False\n",
      "please :  INTJ :  True\n",
      "london :  PROPN :  False\n",
      "6 :  NUM :  False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens_spacy = nlp(line)\n",
    "for token in tokens_spacy:\n",
    "    print(token.text, ': ', token.pos_, ': ', token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c85f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london :  GPE\n",
      "6 :  CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in tokens_spacy.ents:\n",
    "    print(ent.text, ': ', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e65ac",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9dc0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"I am eating pizza and, coke.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3752cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'eating', 'pizza', 'and,', 'coke.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using split()\n",
    "str1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5208ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'eating', 'pizza', 'and', 'coke']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using regex\n",
    "re.findall('[\\w]+',str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bfbb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a68cc35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'eating', 'pizza', 'and', ',', 'coke', '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK- word_tokenize\n",
    "from nltk import word_tokenize\n",
    "word_tokenize(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f133b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'eating', 'pizza', 'and,', 'coke.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK - whitespace tokenizer\n",
    "space_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "space_tokenizer.tokenize(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1df7f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'eating', 'pizza', 'and', 'coke']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK - regex tokenizer\n",
    "reg_tokenizer = nltk.tokenize.RegexpTokenizer('[A-Za-z]+')\n",
    "reg_tokenizer.tokenize(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515c412",
   "metadata": {},
   "source": [
    "## Vectorization/Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017a5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2 = ['I am going to test Covid',\n",
    "        'It seems ABC hospital is doing the Covid test',\n",
    "        'Covaxin is still in WIP phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90005a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# CountVec - count apprearances of a word -> Bag of Words\n",
    "count_vec = CountVectorizer(analyzer='word', ngram_range=(1, 3), stop_words = 'english')\n",
    "count_vec.fit(str2)\n",
    "count = count_vec.transform(str2)\n",
    "vectors = count_vec.get_feature_names()\n",
    "smatrix = count_vec.transform(str2)\n",
    "dense = smatrix.todense()\n",
    "dense_list = dense.tolist()\n",
    "df_countvec = pd.DataFrame(dense_list,columns=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31b0f65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>abc hospital</th>\n",
       "      <th>abc hospital doing</th>\n",
       "      <th>covaxin</th>\n",
       "      <th>covaxin wip</th>\n",
       "      <th>covaxin wip phase</th>\n",
       "      <th>covid</th>\n",
       "      <th>covid test</th>\n",
       "      <th>doing</th>\n",
       "      <th>doing covid</th>\n",
       "      <th>...</th>\n",
       "      <th>going test</th>\n",
       "      <th>going test covid</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hospital doing</th>\n",
       "      <th>hospital doing covid</th>\n",
       "      <th>phase</th>\n",
       "      <th>test</th>\n",
       "      <th>test covid</th>\n",
       "      <th>wip</th>\n",
       "      <th>wip phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abc  abc hospital  abc hospital doing  covaxin  covaxin wip  \\\n",
       "0    0             0                   0        0            0   \n",
       "1    1             1                   1        0            0   \n",
       "2    0             0                   0        1            1   \n",
       "\n",
       "   covaxin wip phase  covid  covid test  doing  doing covid  ...  going test  \\\n",
       "0                  0      1           0      0            0  ...           1   \n",
       "1                  0      1           1      1            1  ...           0   \n",
       "2                  1      0           0      0            0  ...           0   \n",
       "\n",
       "   going test covid  hospital  hospital doing  hospital doing covid  phase  \\\n",
       "0                 1         0               0                     0      0   \n",
       "1                 0         1               1                     1      0   \n",
       "2                 0         0               0                     0      1   \n",
       "\n",
       "   test  test covid  wip  wip phase  \n",
       "0     1           1    0          0  \n",
       "1     1           0    0          0  \n",
       "2     0           0    1          1  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f23d0300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "tfidf_vec = TfidfVectorizer (analyzer='word', ngram_range=(1, 2), stop_words = 'english')\n",
    "tfidf_vec.fit(str2)\n",
    "tfidf = tfidf_vec.transform(str2)\n",
    "vectors = tfidf_vec.get_feature_names()\n",
    "smatrix = tfidf_vec.transform(str2)\n",
    "dense = smatrix.todense()\n",
    "dense_list = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(dense_list,columns=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9541292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc hospital', 'covaxin', 'covaxin wip', 'covid', 'covid test', 'doing', 'doing covid', 'going', 'going test', 'hospital', 'hospital doing', 'phase', 'test', 'test covid', 'wip', 'wip phase']\n"
     ]
    }
   ],
   "source": [
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eed02b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>abc hospital</th>\n",
       "      <th>covaxin</th>\n",
       "      <th>covaxin wip</th>\n",
       "      <th>covid</th>\n",
       "      <th>covid test</th>\n",
       "      <th>doing</th>\n",
       "      <th>doing covid</th>\n",
       "      <th>going</th>\n",
       "      <th>going test</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hospital doing</th>\n",
       "      <th>phase</th>\n",
       "      <th>test</th>\n",
       "      <th>test covid</th>\n",
       "      <th>wip</th>\n",
       "      <th>wip phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266290</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.350139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        abc  abc hospital   covaxin  covaxin wip     covid  covid test  \\\n",
       "0  0.000000      0.000000  0.000000     0.000000  0.373022    0.000000   \n",
       "1  0.350139      0.350139  0.000000     0.000000  0.266290    0.350139   \n",
       "2  0.000000      0.000000  0.447214     0.447214  0.000000    0.000000   \n",
       "\n",
       "      doing  doing covid     going  going test  hospital  hospital doing  \\\n",
       "0  0.000000     0.000000  0.490479    0.490479  0.000000        0.000000   \n",
       "1  0.350139     0.350139  0.000000    0.000000  0.350139        0.350139   \n",
       "2  0.000000     0.000000  0.000000    0.000000  0.000000        0.000000   \n",
       "\n",
       "      phase      test  test covid       wip  wip phase  \n",
       "0  0.000000  0.373022    0.490479  0.000000   0.000000  \n",
       "1  0.000000  0.266290    0.000000  0.000000   0.000000  \n",
       "2  0.447214  0.000000    0.000000  0.447214   0.447214  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29f2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpEnv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
